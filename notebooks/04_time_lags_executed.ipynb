{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Modeling with Time Lags\n",
    "\n",
    "## The Problem with Notebook #3\n",
    "\n",
    "We got R² = 0.36 — not great. Why?\n",
    "\n",
    "**Industrial processes have inertia.** When an operator changes pH at 2pm, the effect doesn't show up in lab results until 4pm or 6pm. By using same-time inputs to predict outputs, we were asking the wrong question.\n",
    "\n",
    "## The Fix: Time-Lagged Features\n",
    "\n",
    "Instead of: `pH(t) → Silica(t)`\n",
    "\n",
    "We try: `pH(t-1), pH(t-2), pH(t-3), pH(t-4) → Silica(t)`\n",
    "\n",
    "We don't know the exact lag, so we include multiple lags and let the model figure out which matters most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:20.252975Z",
     "iopub.status.busy": "2026-01-24T21:48:20.252480Z",
     "iopub.status.idle": "2026-01-24T21:48:23.079965Z",
     "shell.execute_reply": "2026-01-24T21:48:23.078645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 4097 rows, 23 columns\n",
      "Time range: 2017-03-10 01:00:00 to 2017-09-09 23:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the ORIGINAL data (not preprocessed) - we'll do preprocessing after adding lags\n",
    "df = pd.read_csv('../data/processed/mining_hourly.csv', parse_dates=['date'])\n",
    "df = df.set_index('date').sort_index()\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"Time range: {df.index.min()} to {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Feature Groups\n",
    "\n",
    "We'll add lags to the **controllable inputs** — these are what operators change and what has delayed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.121394Z",
     "iopub.status.busy": "2026-01-24T21:48:23.121064Z",
     "iopub.status.idle": "2026-01-24T21:48:23.126442Z",
     "shell.execute_reply": "2026-01-24T21:48:23.125536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncontrollable inputs: 1\n",
      "Controllable inputs: 19\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "target = '% Silica Concentrate'\n",
    "\n",
    "# Features to drop (outputs or redundant)\n",
    "drop_cols = ['% Iron Concentrate', '% Silica Feed']\n",
    "\n",
    "# Uncontrollable - just use current value (ore quality is what it is)\n",
    "uncontrollable = ['% Iron Feed']\n",
    "\n",
    "# Controllable - these have delayed effects, add lags\n",
    "controllable = [\n",
    "    'Starch Flow', 'Amina Flow', \n",
    "    'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "    'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "    'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "    'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "    'Flotation Column 07 Air Flow',\n",
    "    'Flotation Column 01 Level', 'Flotation Column 02 Level',\n",
    "    'Flotation Column 03 Level', 'Flotation Column 04 Level',\n",
    "    'Flotation Column 05 Level', 'Flotation Column 06 Level',\n",
    "    'Flotation Column 07 Level',\n",
    "]\n",
    "\n",
    "print(f\"Uncontrollable inputs: {len(uncontrollable)}\")\n",
    "print(f\"Controllable inputs: {len(controllable)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Time-Lagged Features\n",
    "\n",
    "For each controllable input, we add:\n",
    "- **Lag 1-4**: Value from 1, 2, 3, 4 hours ago\n",
    "- **Rolling mean 4h**: Average over last 4 hours\n",
    "- **Rolling std 4h**: Variability over last 4 hours (process stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.131050Z",
     "iopub.status.busy": "2026-01-24T21:48:23.130743Z",
     "iopub.status.idle": "2026-01-24T21:48:23.186585Z",
     "shell.execute_reply": "2026-01-24T21:48:23.185335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: 23\n",
      "After adding lags: 137\n",
      "\n",
      "New features per controllable input: 4 lags + 2 rolling = 6\n",
      "Total new features: 19 × 6 = 114\n"
     ]
    }
   ],
   "source": [
    "def create_lagged_features(df, columns, max_lag=4):\n",
    "    \"\"\"\n",
    "    Create lagged features for specified columns.\n",
    "    \n",
    "    For each column, creates:\n",
    "    - Lag 1 to max_lag (values from previous hours)\n",
    "    - Rolling mean over max_lag hours\n",
    "    - Rolling std over max_lag hours\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        # Lagged values\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df_new[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "        \n",
    "        # Rolling statistics (looking backward)\n",
    "        df_new[f'{col}_roll_mean_{max_lag}h'] = df[col].shift(1).rolling(window=max_lag).mean()\n",
    "        df_new[f'{col}_roll_std_{max_lag}h'] = df[col].shift(1).rolling(window=max_lag).std()\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Create lagged features for controllable inputs\n",
    "df_lagged = create_lagged_features(df, controllable, max_lag=4)\n",
    "\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"After adding lags: {len(df_lagged.columns)}\")\n",
    "print(f\"\\nNew features per controllable input: 4 lags + 2 rolling = 6\")\n",
    "print(f\"Total new features: {len(controllable)} × 6 = {len(controllable) * 6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.189763Z",
     "iopub.status.busy": "2026-01-24T21:48:23.189414Z",
     "iopub.status.idle": "2026-01-24T21:48:23.203265Z",
     "shell.execute_reply": "2026-01-24T21:48:23.202340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4 rows (needed for lag calculation)\n",
      "Remaining: 4093 rows\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN (first 4 rows won't have lag data)\n",
    "rows_before = len(df_lagged)\n",
    "df_lagged = df_lagged.dropna()\n",
    "rows_after = len(df_lagged)\n",
    "\n",
    "print(f\"Dropped {rows_before - rows_after} rows (needed for lag calculation)\")\n",
    "print(f\"Remaining: {rows_after} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Features for Modeling\n",
    "\n",
    "Now we:\n",
    "1. Drop redundant columns\n",
    "2. Log-transform Starch Flow (and its lagged versions)\n",
    "3. Standardize all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.206231Z",
     "iopub.status.busy": "2026-01-24T21:48:23.205859Z",
     "iopub.status.idle": "2026-01-24T21:48:23.416130Z",
     "shell.execute_reply": "2026-01-24T21:48:23.414635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformed 7 Starch Flow columns\n",
      "\n",
      "Total features: 134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop outputs/redundant\n",
    "df_model = df_lagged.drop(columns=drop_cols)\n",
    "\n",
    "# Log-transform Starch Flow columns (original + all lagged versions)\n",
    "starch_cols = [c for c in df_model.columns if 'Starch Flow' in c]\n",
    "for col in starch_cols:\n",
    "    df_model[col] = np.log1p(df_model[col])\n",
    "\n",
    "print(f\"Log-transformed {len(starch_cols)} Starch Flow columns\")\n",
    "\n",
    "# Define feature columns (everything except target)\n",
    "feature_cols = [c for c in df_model.columns if c != target]\n",
    "\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.418978Z",
     "iopub.status.busy": "2026-01-24T21:48:23.418563Z",
     "iopub.status.idle": "2026-01-24T21:48:23.642865Z",
     "shell.execute_reply": "2026-01-24T21:48:23.641689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4093, 134)\n",
      "y shape: (4093,)\n",
      "\n",
      "Feature stats (should be mean≈0, std≈1):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean  std\n",
      "% Iron Feed    -0.0  1.0\n",
      "Starch Flow     0.0  1.0\n",
      "Amina Flow      0.0  1.0\n",
      "Ore Pulp Flow  -0.0  1.0\n",
      "Ore Pulp pH    -0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "df_model[feature_cols] = scaler.fit_transform(df_model[feature_cols])\n",
    "\n",
    "# Create X and y\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature stats (should be mean≈0, std≈1):\")\n",
    "print(X.describe().T[['mean', 'std']].head(5).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Time-Based Train/Test Split\n",
    "\n",
    "**Important:** For time series, we should NOT use random split.\n",
    "\n",
    "Why? If we randomly mix data, the model might see \"future\" data during training, which is cheating.\n",
    "\n",
    "Instead: Train on first 80% of time, test on last 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.645566Z",
     "iopub.status.busy": "2026-01-24T21:48:23.645255Z",
     "iopub.status.idle": "2026-01-24T21:48:23.651228Z",
     "shell.execute_reply": "2026-01-24T21:48:23.650351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3274 rows (2017-03-10 05:00:00 to 2017-08-06 20:00:00)\n",
      "Test set:     819 rows (2017-08-06 21:00:00 to 2017-09-09 23:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (no shuffling!)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} rows ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Test set:     {len(X_test)} rows ({X_test.index.min()} to {X_test.index.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train with FLAML (Longer Budget)\n",
    "\n",
    "We give it 5 minutes this time — more features need more exploration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:48:23.653835Z",
     "iopub.status.busy": "2026-01-24T21:48:23.653554Z",
     "iopub.status.idle": "2026-01-24T21:53:31.830191Z",
     "shell.execute_reply": "2026-01-24T21:53:31.829001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: extra_tree\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "automl.fit(\n",
    "    X_train, y_train,\n",
    "    task='regression',\n",
    "    metric='r2',\n",
    "    time_budget=300,  # 5 minutes\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest model: {automl.best_estimator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:53:31.833561Z",
     "iopub.status.busy": "2026-01-24T21:53:31.833189Z",
     "iopub.status.idle": "2026-01-24T21:53:31.936446Z",
     "shell.execute_reply": "2026-01-24T21:53:31.935571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEST SET PERFORMANCE (with time lags)\n",
      "==================================================\n",
      "\n",
      "R² Score:  -0.0477\n",
      "RMSE:      1.1716\n",
      "MAE:       0.9982\n",
      "\n",
      "--- Comparison with Notebook #3 ---\n",
      "Without lags: R² = 0.359\n",
      "With lags:    R² = -0.048\n",
      "Improvement:  -113.3%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST SET PERFORMANCE (with time lags)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nR² Score:  {r2:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n",
    "print(f\"MAE:       {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Comparison with Notebook #3 ---\")\n",
    "print(f\"Without lags: R² = 0.359\")\n",
    "print(f\"With lags:    R² = {r2:.3f}\")\n",
    "print(f\"Improvement:  {(r2 - 0.359) / 0.359 * 100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:53:31.939528Z",
     "iopub.status.busy": "2026-01-24T21:53:31.939165Z",
     "iopub.status.idle": "2026-01-24T21:53:32.328956Z",
     "shell.execute_reply": "2026-01-24T21:53:32.327348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Actual % Silica')\n",
    "ax.set_ylabel('Predicted % Silica')\n",
    "ax.set_title(f'Actual vs Predicted (R² = {r2:.3f})')\n",
    "\n",
    "ax = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax.scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted % Silica')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/model_03_lagged_predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Which Lags Matter Most?\n",
    "\n",
    "Feature importance tells us which time lags the model found most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:53:32.332703Z",
     "iopub.status.busy": "2026-01-24T21:53:32.332380Z",
     "iopub.status.idle": "2026-01-24T21:53:32.445982Z",
     "shell.execute_reply": "2026-01-24T21:53:32.444982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features:\n",
      "                                  feature  importance\n",
      "                               Amina Flow    0.017748\n",
      "                              % Iron Feed    0.017410\n",
      "        Flotation Column 04 Air Flow_lag4    0.013650\n",
      "                  Amina Flow_roll_mean_4h    0.013508\n",
      "Flotation Column 01 Air Flow_roll_mean_4h    0.012880\n",
      "        Flotation Column 04 Air Flow_lag1    0.012420\n",
      "            Ore Pulp Density_roll_mean_4h    0.012109\n",
      "Flotation Column 04 Air Flow_roll_mean_4h    0.012068\n",
      "Flotation Column 03 Air Flow_roll_mean_4h    0.011869\n",
      "        Flotation Column 01 Air Flow_lag1    0.011396\n",
      "        Flotation Column 04 Air Flow_lag3    0.011149\n",
      "             Flotation Column 04 Air Flow    0.010937\n",
      "    Flotation Column 03 Level_roll_std_4h    0.010903\n",
      "        Flotation Column 04 Air Flow_lag2    0.010720\n",
      "             Flotation Column 01 Air Flow    0.010430\n",
      "                 Starch Flow_roll_mean_4h    0.010254\n",
      "                          Amina Flow_lag1    0.010247\n",
      "        Flotation Column 03 Air Flow_lag1    0.009731\n",
      "        Flotation Column 01 Air Flow_lag3    0.009670\n",
      "   Flotation Column 03 Level_roll_mean_4h    0.009554\n"
     ]
    }
   ],
   "source": [
    "model = automl.model.estimator\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 20 Most Important Features:\")\n",
    "    print(importance.head(20).to_string(index=False))\n",
    "else:\n",
    "    importance = None\n",
    "    print(\"Feature importance not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:53:32.449036Z",
     "iopub.status.busy": "2026-01-24T21:53:32.448751Z",
     "iopub.status.idle": "2026-01-24T21:53:32.648384Z",
     "shell.execute_reply": "2026-01-24T21:53:32.647145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance by Lag Type:\n",
      "========================================\n",
      "  current (t=0): 0\n",
      "  rolling mean: 0\n",
      "  rolling std: 0\n",
      "  lag1 (1h ago): 0\n",
      "  lag3 (3h ago): 0\n",
      "  lag2 (2h ago): 0\n",
      "  lag4 (4h ago): 0\n"
     ]
    }
   ],
   "source": [
    "# Analyze which lag times are most important\n",
    "if importance is not None:\n",
    "    # Extract lag info from feature names\n",
    "    def get_lag_type(name):\n",
    "        if '_lag1' in name:\n",
    "            return 'lag1 (1h ago)'\n",
    "        elif '_lag2' in name:\n",
    "            return 'lag2 (2h ago)'\n",
    "        elif '_lag3' in name:\n",
    "            return 'lag3 (3h ago)'\n",
    "        elif '_lag4' in name:\n",
    "            return 'lag4 (4h ago)'\n",
    "        elif '_roll_mean' in name:\n",
    "            return 'rolling mean'\n",
    "        elif '_roll_std' in name:\n",
    "            return 'rolling std'\n",
    "        else:\n",
    "            return 'current (t=0)'\n",
    "    \n",
    "    importance['lag_type'] = importance['feature'].apply(get_lag_type)\n",
    "    \n",
    "    lag_importance = importance.groupby('lag_type')['importance'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nImportance by Lag Type:\")\n",
    "    print(\"=\"*40)\n",
    "    for lag, imp in lag_importance.items():\n",
    "        print(f\"  {lag}: {imp:.0f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    lag_importance.plot(kind='bar', ax=ax, color='steelblue')\n",
    "    ax.set_ylabel('Total Importance')\n",
    "    ax.set_title('Which Time Lags Matter Most?')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/model_04_lag_importance.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Changed:\n",
    "1. Added lagged features (1-4 hours) for controllable inputs\n",
    "2. Added rolling mean and std (process stability)\n",
    "3. Used time-based split instead of random split\n",
    "4. Increased FLAML budget to 5 minutes\n",
    "\n",
    "### Key Insight:\n",
    "The lag analysis tells us the **process response time** — how long after a change do we see the effect in output quality.\n",
    "\n",
    "### For Operators:\n",
    "If lag2 or lag3 features are most important, it means changes take 2-3 hours to show up in lab results. This affects how they should:\n",
    "- Time their adjustments\n",
    "- Interpret feedback\n",
    "- Avoid over-correcting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
