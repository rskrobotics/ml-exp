{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Building with AutoML (FLAML)\n",
    "\n",
    "## What we're doing\n",
    "\n",
    "We want to predict **% Silica Concentrate** (our quality metric) from process inputs.\n",
    "\n",
    "Instead of assuming a specific algorithm, we'll use **FLAML** (Fast and Lightweight AutoML) to:\n",
    "1. Try multiple algorithms automatically\n",
    "2. Tune hyperparameters for each\n",
    "3. Pick the best one based on validation performance\n",
    "\n",
    "## What is FLAML?\n",
    "\n",
    "FLAML is Microsoft's AutoML library. It's:\n",
    "- **Fast**: Uses smart search, not brute force\n",
    "- **Lightweight**: Minimal dependencies\n",
    "- **Automatic**: Handles model selection + hyperparameter tuning\n",
    "\n",
    "### Algorithms FLAML tries:\n",
    "| Algorithm | Type | Strengths |\n",
    "|-----------|------|----------|\n",
    "| LightGBM | Gradient boosted trees | Fast, handles large data |\n",
    "| XGBoost | Gradient boosted trees | Robust, widely used |\n",
    "| Random Forest | Ensemble of trees | Stable, less overfitting |\n",
    "| Extra Trees | Ensemble of trees | More randomness, faster |\n",
    "| Linear/Ridge | Linear regression | Simple baseline |\n",
    "| CatBoost | Gradient boosted trees | Great with categoricals |\n",
    "\n",
    "FLAML allocates more time to promising algorithms and less to poor ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Preprocessed Data\n",
    "\n",
    "From notebook #2, we created `mining_automl_ready.csv` which has:\n",
    "- Redundant features dropped (% Silica Feed, % Iron Concentrate)\n",
    "- Starch Flow log-transformed (was heavily skewed)\n",
    "- All features standardized (mean=0, std=1)\n",
    "\n",
    "**Why standardize?** AutoML tries multiple model types:\n",
    "- Tree-based models (XGBoost, LightGBM) don't need it, but aren't hurt by it\n",
    "- Linear models, SVM, neural nets **require** standardized data\n",
    "\n",
    "By standardizing, we ensure ALL model types have a fair chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 4097 rows, 21 columns\n",
      "\n",
      "Features (20): standardized, ready for any model type\n",
      "Target: % Silica Concentrate (NOT standardized - in original units)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Iron Feed</th>\n",
       "      <th>Starch Flow</th>\n",
       "      <th>Amina Flow</th>\n",
       "      <th>Ore Pulp Flow</th>\n",
       "      <th>Ore Pulp pH</th>\n",
       "      <th>Ore Pulp Density</th>\n",
       "      <th>Flotation Column 01 Air Flow</th>\n",
       "      <th>Flotation Column 02 Air Flow</th>\n",
       "      <th>Flotation Column 03 Air Flow</th>\n",
       "      <th>Flotation Column 04 Air Flow</th>\n",
       "      <th>...</th>\n",
       "      <th>Flotation Column 06 Air Flow</th>\n",
       "      <th>Flotation Column 07 Air Flow</th>\n",
       "      <th>Flotation Column 01 Level</th>\n",
       "      <th>Flotation Column 02 Level</th>\n",
       "      <th>Flotation Column 03 Level</th>\n",
       "      <th>Flotation Column 04 Level</th>\n",
       "      <th>Flotation Column 05 Level</th>\n",
       "      <th>Flotation Column 06 Level</th>\n",
       "      <th>Flotation Column 07 Level</th>\n",
       "      <th>% Silica Concentrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.212251</td>\n",
       "      <td>0.404113</td>\n",
       "      <td>1.083194</td>\n",
       "      <td>0.140386</td>\n",
       "      <td>0.914982</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>-0.985665</td>\n",
       "      <td>-0.915495</td>\n",
       "      <td>-1.089311</td>\n",
       "      <td>-1.793315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.379915</td>\n",
       "      <td>-1.489760</td>\n",
       "      <td>-0.571874</td>\n",
       "      <td>-0.652849</td>\n",
       "      <td>-0.583654</td>\n",
       "      <td>0.386426</td>\n",
       "      <td>0.407072</td>\n",
       "      <td>0.456197</td>\n",
       "      <td>0.406791</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.212251</td>\n",
       "      <td>0.381629</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>0.274018</td>\n",
       "      <td>0.957985</td>\n",
       "      <td>-0.197532</td>\n",
       "      <td>-1.029399</td>\n",
       "      <td>-0.915904</td>\n",
       "      <td>-1.094421</td>\n",
       "      <td>-1.793315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.424620</td>\n",
       "      <td>-1.501172</td>\n",
       "      <td>-0.580146</td>\n",
       "      <td>-0.623916</td>\n",
       "      <td>-0.586492</td>\n",
       "      <td>0.391865</td>\n",
       "      <td>0.312846</td>\n",
       "      <td>0.338555</td>\n",
       "      <td>0.418576</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.212251</td>\n",
       "      <td>0.634220</td>\n",
       "      <td>1.239983</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.820657</td>\n",
       "      <td>-1.019853</td>\n",
       "      <td>-0.919639</td>\n",
       "      <td>-1.093962</td>\n",
       "      <td>-1.793315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.413380</td>\n",
       "      <td>-1.479619</td>\n",
       "      <td>-0.575238</td>\n",
       "      <td>-0.618578</td>\n",
       "      <td>-0.580570</td>\n",
       "      <td>0.402535</td>\n",
       "      <td>0.344986</td>\n",
       "      <td>0.397891</td>\n",
       "      <td>0.403538</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.212251</td>\n",
       "      <td>0.453448</td>\n",
       "      <td>1.255080</td>\n",
       "      <td>0.273440</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.794703</td>\n",
       "      <td>-1.018239</td>\n",
       "      <td>-0.916220</td>\n",
       "      <td>-1.091336</td>\n",
       "      <td>-1.793315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427471</td>\n",
       "      <td>-1.491618</td>\n",
       "      <td>-0.264436</td>\n",
       "      <td>-0.268758</td>\n",
       "      <td>-0.317273</td>\n",
       "      <td>0.969060</td>\n",
       "      <td>0.938527</td>\n",
       "      <td>0.964562</td>\n",
       "      <td>1.018911</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.212251</td>\n",
       "      <td>0.526425</td>\n",
       "      <td>1.572251</td>\n",
       "      <td>0.243344</td>\n",
       "      <td>-0.057179</td>\n",
       "      <td>1.340809</td>\n",
       "      <td>-1.028134</td>\n",
       "      <td>-0.917724</td>\n",
       "      <td>-1.095120</td>\n",
       "      <td>-1.793315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.413128</td>\n",
       "      <td>-1.494520</td>\n",
       "      <td>0.235650</td>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.130673</td>\n",
       "      <td>1.693140</td>\n",
       "      <td>1.656277</td>\n",
       "      <td>1.731899</td>\n",
       "      <td>1.781621</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   % Iron Feed  Starch Flow  Amina Flow  Ore Pulp Flow  Ore Pulp pH  \\\n",
       "0    -0.212251     0.404113    1.083194       0.140386     0.914982   \n",
       "1    -0.212251     0.381629    0.586454       0.274018     0.957985   \n",
       "2    -0.212251     0.634220    1.239983       0.141633     0.742794   \n",
       "3    -0.212251     0.453448    1.255080       0.273440     0.399418   \n",
       "4    -0.212251     0.526425    1.572251       0.243344    -0.057179   \n",
       "\n",
       "   Ore Pulp Density  Flotation Column 01 Air Flow  \\\n",
       "0          0.771216                     -0.985665   \n",
       "1         -0.197532                     -1.029399   \n",
       "2          0.820657                     -1.019853   \n",
       "3          0.794703                     -1.018239   \n",
       "4          1.340809                     -1.028134   \n",
       "\n",
       "   Flotation Column 02 Air Flow  Flotation Column 03 Air Flow  \\\n",
       "0                     -0.915495                     -1.089311   \n",
       "1                     -0.915904                     -1.094421   \n",
       "2                     -0.919639                     -1.093962   \n",
       "3                     -0.916220                     -1.091336   \n",
       "4                     -0.917724                     -1.095120   \n",
       "\n",
       "   Flotation Column 04 Air Flow  ...  Flotation Column 06 Air Flow  \\\n",
       "0                     -1.793315  ...                     -1.379915   \n",
       "1                     -1.793315  ...                     -1.424620   \n",
       "2                     -1.793315  ...                     -1.413380   \n",
       "3                     -1.793315  ...                     -1.427471   \n",
       "4                     -1.793315  ...                     -1.413128   \n",
       "\n",
       "   Flotation Column 07 Air Flow  Flotation Column 01 Level  \\\n",
       "0                     -1.489760                  -0.571874   \n",
       "1                     -1.501172                  -0.580146   \n",
       "2                     -1.479619                  -0.575238   \n",
       "3                     -1.491618                  -0.264436   \n",
       "4                     -1.494520                   0.235650   \n",
       "\n",
       "   Flotation Column 02 Level  Flotation Column 03 Level  \\\n",
       "0                  -0.652849                  -0.583654   \n",
       "1                  -0.623916                  -0.586492   \n",
       "2                  -0.618578                  -0.580570   \n",
       "3                  -0.268758                  -0.317273   \n",
       "4                   0.235556                   0.130673   \n",
       "\n",
       "   Flotation Column 04 Level  Flotation Column 05 Level  \\\n",
       "0                   0.386426                   0.407072   \n",
       "1                   0.391865                   0.312846   \n",
       "2                   0.402535                   0.344986   \n",
       "3                   0.969060                   0.938527   \n",
       "4                   1.693140                   1.656277   \n",
       "\n",
       "   Flotation Column 06 Level  Flotation Column 07 Level  % Silica Concentrate  \n",
       "0                   0.456197                   0.406791                  1.31  \n",
       "1                   0.338555                   0.418576                  1.11  \n",
       "2                   0.397891                   0.403538                  1.27  \n",
       "3                   0.964562                   1.018911                  1.36  \n",
       "4                   1.731899                   1.781621                  1.34  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load preprocessed data (standardized, redundant features removed)\n",
    "# Note: date column not included - not needed for modeling\n",
    "df = pd.read_csv('../data/processed/mining_automl_ready.csv')\n",
    "\n",
    "# Load feature names and scaler (saved from notebook #2)\n",
    "feature_names = joblib.load('../data/processed/feature_names.joblib')\n",
    "scaler = joblib.load('../data/processed/feature_scaler.joblib')\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nFeatures ({len(feature_names)}): standardized, ready for any model type\")\n",
    "print(f\"Target: % Silica Concentrate (NOT standardized - in original units)\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4097, 20)\n",
      "y shape: (4097,)\n",
      "\n",
      "Feature statistics (should be mean≈0, std≈1):\n",
      "               mean  std\n",
      "% Iron Feed    -0.0  1.0\n",
      "Starch Flow     0.0  1.0\n",
      "Amina Flow      0.0  1.0\n",
      "Ore Pulp Flow  -0.0  1.0\n",
      "Ore Pulp pH    -0.0  1.0\n",
      "\n",
      "Target statistics (NOT standardized - original units):\n",
      "  Mean: 2.33%\n",
      "  Std:  1.12%\n"
     ]
    }
   ],
   "source": [
    "# Define target and features (using saved feature names)\n",
    "target = '% Silica Concentrate'\n",
    "features = feature_names  # loaded from preprocessing step\n",
    "\n",
    "# Create X (inputs) and y (output)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Verify standardization worked (features should have mean≈0, std≈1)\n",
    "print(f\"\\nFeature statistics (should be mean≈0, std≈1):\")\n",
    "print(X.describe().T[['mean', 'std']].head(5).round(3))\n",
    "\n",
    "print(f\"\\nTarget statistics (NOT standardized - original units):\")\n",
    "print(f\"  Mean: {y.mean():.2f}%\")\n",
    "print(f\"  Std:  {y.std():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train/Test Split\n",
    "\n",
    "### Why split the data?\n",
    "\n",
    "We need to evaluate how well our model works on **data it hasn't seen**.\n",
    "\n",
    "- **Training set (80%)**: Model learns from this\n",
    "- **Test set (20%)**: We evaluate on this — model never sees it during training\n",
    "\n",
    "If we evaluated on training data, the model could just memorize answers (overfitting).\n",
    "\n",
    "### Time series consideration\n",
    "\n",
    "Our data is time-ordered. For true production use, we'd want to:\n",
    "- Train on past data\n",
    "- Test on future data\n",
    "\n",
    "For this prototype, we'll use random split — simpler and fine for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3277 rows\n",
      "Test set:     820 rows\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80% train, 20% test, random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set:     {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train with FLAML AutoML\n",
    "\n",
    "### What happens inside FLAML:\n",
    "\n",
    "1. **Starts with cheap models** (linear regression, small trees)\n",
    "2. **Estimates performance** quickly using cross-validation\n",
    "3. **Allocates more time** to promising algorithms\n",
    "4. **Tunes hyperparameters** for each algorithm it tries\n",
    "5. **Returns the best model** found within time budget\n",
    "\n",
    "### Key parameters:\n",
    "\n",
    "| Parameter | What it does |\n",
    "|-----------|-------------|\n",
    "| `time_budget` | How long to search (seconds) |\n",
    "| `metric` | What to optimize (r2, rmse, mae) |\n",
    "| `task` | 'regression' or 'classification' |\n",
    "| `estimator_list` | Which algorithms to try |\n",
    "\n",
    "We'll give it 60 seconds to search — enough to try multiple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "# Create AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Configure and run\n",
    "automl.fit(\n",
    "    X_train, y_train,\n",
    "    task='regression',           # we're predicting a continuous value\n",
    "    metric='r2',                 # optimize for R² (higher = better)\n",
    "    time_budget=60,              # search for 60 seconds\n",
    "    verbose=1,                   # show progress\n",
    "    seed=42,                     # reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Results — What did FLAML find?\n",
    "\n",
    "Let's see which algorithm won and how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BEST MODEL FOUND\n",
      "==================================================\n",
      "\n",
      "Algorithm: lgbm\n",
      "\n",
      "Best hyperparameters:\n",
      "  n_estimators: 2318\n",
      "  num_leaves: 34\n",
      "  min_child_samples: 6\n",
      "  learning_rate: 0.01921057990310202\n",
      "  log_max_bin: 9\n",
      "  colsample_bytree: 0.7333657199833747\n",
      "  reg_alpha: 0.00682115245814188\n",
      "  reg_lambda: 0.026798931149202433\n"
     ]
    }
   ],
   "source": [
    "# Best model found\n",
    "print(\"=\" * 50)\n",
    "print(\"BEST MODEL FOUND\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nAlgorithm: {automl.best_estimator}\")\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for param, value in automl.best_config.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate on Test Set\n",
    "\n",
    "### Metrics we'll use:\n",
    "\n",
    "| Metric | What it means | Good value |\n",
    "|--------|--------------|------------|\n",
    "| **R²** | % of variance explained (0-1) | >0.7 is decent, >0.9 is great |\n",
    "| **RMSE** | Average error in same units as target | Lower is better |\n",
    "| **MAE** | Average absolute error | Lower is better, easier to interpret |\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **R² = 0.8** means: model explains 80% of the variance in silica concentrate\n",
    "- **RMSE = 0.2** means: predictions are off by ~0.2% silica on average\n",
    "- **MAE = 0.15** means: typical error is 0.15% silica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEST SET PERFORMANCE\n",
      "==================================================\n",
      "\n",
      "R² Score:  0.3590\n",
      "RMSE:      0.9113\n",
      "MAE:       0.6824\n",
      "\n",
      "--- Interpretation ---\n",
      "Model explains 35.9% of variance in % Silica Concentrate\n",
      "Average prediction error: 0.682% silica\n",
      "Target range in data: 0.6 - 5.5%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nR² Score:  {r2:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n",
    "print(f\"MAE:       {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Interpretation ---\")\n",
    "print(f\"Model explains {r2*100:.1f}% of variance in % Silica Concentrate\")\n",
    "print(f\"Average prediction error: {mae:.3f}% silica\")\n",
    "print(f\"Target range in data: {y.min():.1f} - {y.max():.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: data/processed/model_01_predictions.png\n"
     ]
    }
   ],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax = axes[0]\n",
    "ax.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual % Silica Concentrate')\n",
    "ax.set_ylabel('Predicted % Silica Concentrate')\n",
    "ax.set_title(f'Actual vs Predicted (R² = {r2:.3f})')\n",
    "ax.legend()\n",
    "\n",
    "# Residuals (errors)\n",
    "ax = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax.scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted % Silica Concentrate')\n",
    "ax.set_ylabel('Residual (Actual - Predicted)')\n",
    "ax.set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/model_01_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nSaved: data/processed/model_01_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read these plots:\n",
    "\n",
    "**Left plot (Actual vs Predicted):**\n",
    "- Points on the red dashed line = perfect predictions\n",
    "- Scatter around the line = prediction error\n",
    "- Tighter scatter = better model\n",
    "\n",
    "**Right plot (Residuals):**\n",
    "- Should look like random noise around zero\n",
    "- Patterns in residuals = model is missing something\n",
    "- Funnel shape = error depends on prediction value (heteroscedasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Feature Importance\n",
    "\n",
    "### What is feature importance?\n",
    "\n",
    "It tells us **which inputs matter most** for predictions.\n",
    "\n",
    "For tree-based models, importance = how much each feature reduces prediction error when used for splits.\n",
    "\n",
    "### Why it matters for optimization:\n",
    "\n",
    "- High importance + controllable → **lever you can pull**\n",
    "- High importance + uncontrollable → explains variance but can't optimize\n",
    "- Low importance → doesn't affect output much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (top 10):\n",
      "                     feature  importance\n",
      "                 Ore Pulp pH        4784\n",
      "                 Starch Flow        4430\n",
      "                  Amina Flow        4308\n",
      "Flotation Column 03 Air Flow        4217\n",
      "Flotation Column 01 Air Flow        4102\n",
      "               Ore Pulp Flow        4093\n",
      "Flotation Column 02 Air Flow        4085\n",
      "   Flotation Column 03 Level        3954\n",
      "            Ore Pulp Density        3942\n",
      "Flotation Column 05 Air Flow        3897\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance from the best model\n",
    "# Note: Not all models have feature_importances_, so we handle that\n",
    "\n",
    "model = automl.model.estimator\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Feature Importance (top 10):\")\n",
    "    print(importance.head(10).to_string(index=False))\n",
    "else:\n",
    "    # For linear models, use coefficients\n",
    "    if hasattr(model, 'coef_'):\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': np.abs(model.coef_)\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(\"Feature Importance (absolute coefficients):\")\n",
    "        print(importance.head(10).to_string(index=False))\n",
    "    else:\n",
    "        importance = None\n",
    "        print(\"Feature importance not available for this model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: data/processed/model_02_importance.png\n"
     ]
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "if importance is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Color by controllability\n",
    "    controllable = ['Starch Flow', 'Amina Flow', 'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density']\n",
    "    controllable += [f'Flotation Column 0{i} Air Flow' for i in range(1, 8)]\n",
    "    controllable += [f'Flotation Column 0{i} Level' for i in range(1, 8)]\n",
    "    \n",
    "    colors = ['green' if f in controllable else 'orange' for f in importance['feature']]\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=importance,\n",
    "        x='importance', \n",
    "        y='feature',\n",
    "        hue='feature',\n",
    "        palette=colors,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_title('Feature Importance (Green = Controllable, Orange = Uncontrollable)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/model_02_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nSaved: data/processed/model_02_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare what FLAML tried\n",
    "\n",
    "Let's see all the algorithms FLAML evaluated and how they compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ALL MODELS EVALUATED\n",
      "==================================================\n",
      "\n",
      "Best config found per algorithm:\n",
      "\n",
      "lgbm:\n",
      "    n_estimators: 2318\n",
      "    num_leaves: 34\n",
      "    min_child_samples: 6\n",
      "    learning_rate: 0.01921057990310202\n",
      "    log_max_bin: 9\n",
      "    colsample_bytree: 0.7333657199833747\n",
      "    reg_alpha: 0.00682115245814188\n",
      "    reg_lambda: 0.026798931149202433\n",
      "\n",
      "rf:\n",
      "    n_estimators: 23\n",
      "    max_features: 1.0\n",
      "    max_leaves: 12\n",
      "\n",
      "xgboost:\n",
      "    n_estimators: 100\n",
      "    max_leaves: 14\n",
      "    min_child_weight: 0.06169806162467062\n",
      "    learning_rate: 0.11183666490279637\n",
      "    subsample: 1.0\n",
      "    colsample_bylevel: 0.8686106651969953\n",
      "    colsample_bytree: 0.9855946937981651\n",
      "    reg_alpha: 0.0009765625\n",
      "    reg_lambda: 0.026172971513902767\n",
      "\n",
      "extra_tree:\n",
      "    n_estimators: 11\n",
      "    max_features: 1.0\n",
      "    max_leaves: 29\n",
      "\n",
      "xgb_limitdepth:\n",
      "    n_estimators: 27\n",
      "    max_depth: 5\n",
      "    min_child_weight: 1.7687572479859561\n",
      "    learning_rate: 0.14073492405525717\n",
      "    subsample: 0.9215040509386039\n",
      "    colsample_bylevel: 0.928235678013149\n",
      "    colsample_bytree: 0.9414474294855173\n",
      "    reg_alpha: 0.0009765625\n",
      "    reg_lambda: 1.802275848203579\n",
      "\n",
      "sgd:\n",
      "    penalty: None\n",
      "    alpha: 2.151763355070055e-05\n",
      "    l1_ratio: 0.01121248234072323\n",
      "    epsilon: 0.1\n",
      "    learning_rate: invscaling\n",
      "    eta0: 0.009906549205239458\n",
      "    power_t: 0.15972172227587023\n",
      "    average: False\n",
      "    loss: squared_error\n",
      "\n",
      "\n",
      "Final winner: lgbm\n",
      "Best validation R²: 0.6601895436508679\n"
     ]
    }
   ],
   "source": [
    "# All models tried during search\n",
    "print(\"=\" * 50)\n",
    "print(\"ALL MODELS EVALUATED\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get search history if available\n",
    "if hasattr(automl, 'best_config_per_estimator'):\n",
    "    print(\"\\nBest config found per algorithm:\")\n",
    "    for estimator, config in automl.best_config_per_estimator.items():\n",
    "        if config:\n",
    "            print(f\"\\n{estimator}:\")\n",
    "            for k, v in config.items():\n",
    "                print(f\"    {k}: {v}\")\n",
    "\n",
    "print(f\"\\n\\nFinal winner: {automl.best_estimator}\")\n",
    "print(f\"Best validation R²: {automl.best_loss if automl.best_loss else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What we did:\n",
    "1. Loaded **preprocessed** data from EDA (standardized, redundant features removed)\n",
    "2. Defined inputs (X) and output (y) - features already prepared for any model type\n",
    "3. Split into train/test sets\n",
    "4. Used FLAML to automatically try multiple algorithms (trees, linear, etc.)\n",
    "5. Evaluated on held-out test data\n",
    "6. Analyzed feature importance\n",
    "\n",
    "### Why preprocessing mattered:\n",
    "- **Standardization** let linear models compete fairly with tree models\n",
    "- **Log-transform on Starch Flow** helped linear models handle the skewed distribution\n",
    "- **Dropping % Silica Feed** removed redundancy that could hurt linear models\n",
    "\n",
    "### What we learned:\n",
    "- Which algorithm works best for this data\n",
    "- How accurate our predictions are (R², RMSE)\n",
    "- Which features matter most for prediction\n",
    "- Which controllable features we can use for optimization\n",
    "\n",
    "### Next steps:\n",
    "- **If performance is good**: Use model for \"what-if\" simulations\n",
    "- **If performance is poor**: Try feature engineering, more data, or different approach\n",
    "- **For production**: More rigorous validation (cross-validation, time-based splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL SUMMARY\n",
      "==================================================\n",
      "\n",
      "Best algorithm: lgbm\n",
      "Test R²:        0.3590\n",
      "Test RMSE:      0.9113\n",
      "Test MAE:       0.6824\n",
      "\n",
      "Interpretation:\n",
      "  Model explains 35.9% of silica concentrate variance\n",
      "  Typical prediction error: ±0.682% silica\n",
      "\n",
      "Top controllable features:\n",
      "  - Ore Pulp pH\n",
      "  - Starch Flow\n",
      "  - Amina Flow\n",
      "  - Flotation Column 03 Air Flow\n",
      "  - Flotation Column 01 Air Flow\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nBest algorithm: {automl.best_estimator}\")\n",
    "print(f\"Test R²:        {r2:.4f}\")\n",
    "print(f\"Test RMSE:      {rmse:.4f}\")\n",
    "print(f\"Test MAE:       {mae:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  Model explains {r2*100:.1f}% of silica concentrate variance\")\n",
    "print(f\"  Typical prediction error: ±{mae:.3f}% silica\")\n",
    "\n",
    "if importance is not None:\n",
    "    top_controllable = [f for f in importance.head(5)['feature'] if f in controllable]\n",
    "    if top_controllable:\n",
    "        print(f\"\\nTop controllable features:\")\n",
    "        for f in top_controllable:\n",
    "            print(f\"  - {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
