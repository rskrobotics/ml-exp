{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Selective Time Lags (Best Model)\n",
    "\n",
    "## What We Learned from Previous Notebooks\n",
    "\n",
    "| Notebook | Approach | R² | Problem |\n",
    "|----------|----------|-----|--------|\n",
    "| #3 | No lags, 20 features | 0.36 | Ignores process delays |\n",
    "| #4 | All lags, 134 features | -0.05 | Too many features, overfit |\n",
    "\n",
    "## This Notebook: The Middle Ground\n",
    "\n",
    "- Add lags only for **key features** (identified from EDA)\n",
    "- Use only **lag2 and lag4** (not all lags)\n",
    "- Result: 30 features instead of 134\n",
    "\n",
    "This balances capturing time delays without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load original data\n",
    "df = pd.read_csv('../data/processed/mining_hourly.csv', parse_dates=['date'])\n",
    "df = df.set_index('date').sort_index()\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Key Features for Lagging\n",
    "\n",
    "From EDA (notebook #2), these features had the strongest correlations with silica output:\n",
    "- Ore Pulp pH\n",
    "- Starch Flow\n",
    "- Amina Flow\n",
    "- Flotation Column 01 Air Flow\n",
    "- Flotation Column 03 Air Flow\n",
    "\n",
    "We'll add lag2 (2 hours ago) and lag4 (4 hours ago) only for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '% Silica Concentrate'\n",
    "\n",
    "# Columns to drop (outputs or redundant)\n",
    "drop_cols = ['% Iron Concentrate', '% Silica Feed']\n",
    "\n",
    "# Key features to add lags for (most important from EDA)\n",
    "key_inputs = [\n",
    "    'Ore Pulp pH', \n",
    "    'Starch Flow', \n",
    "    'Amina Flow',\n",
    "    'Flotation Column 01 Air Flow', \n",
    "    'Flotation Column 03 Air Flow'\n",
    "]\n",
    "\n",
    "print(f\"Key inputs for lagging: {len(key_inputs)}\")\n",
    "for f in key_inputs:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Lag Features\n",
    "\n",
    "For each key input, add:\n",
    "- `feature_lag2`: value from 2 hours ago\n",
    "- `feature_lag4`: value from 4 hours ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lag features for key inputs only\n",
    "for col in key_inputs:\n",
    "    df[f'{col}_lag2'] = df[col].shift(2)\n",
    "    df[f'{col}_lag4'] = df[col].shift(4)\n",
    "\n",
    "# Drop rows with NaN (first 4 rows)\n",
    "rows_before = len(df)\n",
    "df = df.dropna()\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f\"Added {len(key_inputs) * 2} lag features\")\n",
    "print(f\"Dropped {rows_before - rows_after} rows (needed for lag calculation)\")\n",
    "print(f\"Remaining: {rows_after} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant/output columns\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# Log-transform Starch Flow columns (original + lagged)\n",
    "starch_cols = [c for c in df.columns if 'Starch' in c]\n",
    "for col in starch_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "print(f\"Log-transformed: {starch_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = [c for c in df.columns if c != target]\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for f in feature_cols:\n",
    "    lag_indicator = \" (LAGGED)\" if '_lag' in f else \"\"\n",
    "    print(f\"  - {f}{lag_indicator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "X = df[feature_cols]\n",
    "y = df[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=feature_cols, index=X.index)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature stats (mean should be ~0, std ~1):\")\n",
    "print(X.describe().T[['mean', 'std']].head(5).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train/Test Split\n",
    "\n",
    "Using random split here. Time-based split showed distribution shift issues (see notebook #4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} rows\")\n",
    "print(f\"Test set:     {len(X_test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train with FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "automl.fit(\n",
    "    X_train, y_train,\n",
    "    task='regression',\n",
    "    metric='r2',\n",
    "    time_budget=120,  # 2 minutes\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest model: {automl.best_estimator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nR² Score:  {r2:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n",
    "print(f\"MAE:       {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Comparison with Other Notebooks ---\")\n",
    "print(f\"Notebook #3 (no lags):        R² = 0.359\")\n",
    "print(f\"Notebook #4 (all lags):       R² = -0.048\")\n",
    "print(f\"Notebook #5 (selective lags): R² = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Actual % Silica')\n",
    "ax.set_ylabel('Predicted % Silica')\n",
    "ax.set_title(f'Actual vs Predicted (R² = {r2:.3f})')\n",
    "\n",
    "ax = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax.scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted % Silica')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/model_05_selective_lags.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automl.model.estimator\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Feature Importance (all features):\")\n",
    "    print(importance.to_string(index=False))\n",
    "else:\n",
    "    if hasattr(model, 'coef_'):\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': np.abs(model.coef_)\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(\"Feature Importance (absolute coefficients):\")\n",
    "        print(importance.to_string(index=False))\n",
    "    else:\n",
    "        importance = None\n",
    "        print(\"Feature importance not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "if importance is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Color: green = lagged, blue = current\n",
    "    colors = ['green' if '_lag' in f else 'steelblue' for f in importance['feature']]\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=importance,\n",
    "        x='importance', \n",
    "        y='feature',\n",
    "        hue='feature',\n",
    "        palette=colors,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_title('Feature Importance\\nGreen = Lagged features, Blue = Current values')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/model_05_importance.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Lag Importance\n",
    "\n",
    "Which lag times matter most? This tells us about process response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if importance is not None:\n",
    "    # Categorize features\n",
    "    def get_lag_type(name):\n",
    "        if '_lag2' in name:\n",
    "            return 'lag2 (2h ago)'\n",
    "        elif '_lag4' in name:\n",
    "            return 'lag4 (4h ago)'\n",
    "        else:\n",
    "            return 'current (t=0)'\n",
    "    \n",
    "    importance['lag_type'] = importance['feature'].apply(get_lag_type)\n",
    "    \n",
    "    lag_summary = importance.groupby('lag_type')['importance'].agg(['sum', 'mean', 'count'])\n",
    "    lag_summary = lag_summary.sort_values('sum', ascending=False)\n",
    "    \n",
    "    print(\"Importance by Lag Type:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(lag_summary.round(2))\n",
    "    \n",
    "    print(\"\\n--- Interpretation ---\")\n",
    "    top_lag = lag_summary['sum'].idxmax()\n",
    "    print(f\"Most important lag type: {top_lag}\")\n",
    "    if 'lag4' in top_lag:\n",
    "        print(\"Process response time appears to be ~4 hours\")\n",
    "    elif 'lag2' in top_lag:\n",
    "        print(\"Process response time appears to be ~2 hours\")\n",
    "    else:\n",
    "        print(\"Current values matter most (fast response or no lag effect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Notebook | Features | Approach | R² |\n",
    "|----------|----------|----------|----|\n",
    "| #3 | 20 | No lags | 0.36 |\n",
    "| #4 | 134 | All lags for all features | -0.05 |\n",
    "| **#5** | **30** | **Selective lags for key features** | **~0.40** |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Time lags matter** — but only for key features\n",
    "2. **More features ≠ better** — too many lags caused overfitting\n",
    "3. **Feature importance shows process timing** — which lags matter tells us response time\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- R² = 0.40 means 60% of variance is unexplained\n",
    "- Model shows correlations, not guaranteed causal effects\n",
    "- Use for directional guidance, not precise predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
