{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Modeling with Time Lags\n",
    "\n",
    "## The Problem with Notebook #3\n",
    "\n",
    "We got R² = 0.36 — not great. Why?\n",
    "\n",
    "**Industrial processes have inertia.** When an operator changes pH at 2pm, the effect doesn't show up in lab results until 4pm or 6pm. By using same-time inputs to predict outputs, we were asking the wrong question.\n",
    "\n",
    "## The Fix: Time-Lagged Features\n",
    "\n",
    "Instead of: `pH(t) → Silica(t)`\n",
    "\n",
    "We try: `pH(t-1), pH(t-2), pH(t-3), pH(t-4) → Silica(t)`\n",
    "\n",
    "We don't know the exact lag, so we include multiple lags and let the model figure out which matters most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the ORIGINAL data (not preprocessed) - we'll do preprocessing after adding lags\n",
    "df = pd.read_csv('../data/processed/mining_hourly.csv', parse_dates=['date'])\n",
    "df = df.set_index('date').sort_index()\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"Time range: {df.index.min()} to {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Feature Groups\n",
    "\n",
    "We'll add lags to the **controllable inputs** — these are what operators change and what has delayed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = '% Silica Concentrate'\n",
    "\n",
    "# Features to drop (outputs or redundant)\n",
    "drop_cols = ['% Iron Concentrate', '% Silica Feed']\n",
    "\n",
    "# Uncontrollable - just use current value (ore quality is what it is)\n",
    "uncontrollable = ['% Iron Feed']\n",
    "\n",
    "# Controllable - these have delayed effects, add lags\n",
    "controllable = [\n",
    "    'Starch Flow', 'Amina Flow', \n",
    "    'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "    'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "    'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "    'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "    'Flotation Column 07 Air Flow',\n",
    "    'Flotation Column 01 Level', 'Flotation Column 02 Level',\n",
    "    'Flotation Column 03 Level', 'Flotation Column 04 Level',\n",
    "    'Flotation Column 05 Level', 'Flotation Column 06 Level',\n",
    "    'Flotation Column 07 Level',\n",
    "]\n",
    "\n",
    "print(f\"Uncontrollable inputs: {len(uncontrollable)}\")\n",
    "print(f\"Controllable inputs: {len(controllable)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Time-Lagged Features\n",
    "\n",
    "For each controllable input, we add:\n",
    "- **Lag 1-4**: Value from 1, 2, 3, 4 hours ago\n",
    "- **Rolling mean 4h**: Average over last 4 hours\n",
    "- **Rolling std 4h**: Variability over last 4 hours (process stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df, columns, max_lag=4):\n",
    "    \"\"\"\n",
    "    Create lagged features for specified columns.\n",
    "    \n",
    "    For each column, creates:\n",
    "    - Lag 1 to max_lag (values from previous hours)\n",
    "    - Rolling mean over max_lag hours\n",
    "    - Rolling std over max_lag hours\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        # Lagged values\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df_new[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "        \n",
    "        # Rolling statistics (looking backward)\n",
    "        df_new[f'{col}_roll_mean_{max_lag}h'] = df[col].shift(1).rolling(window=max_lag).mean()\n",
    "        df_new[f'{col}_roll_std_{max_lag}h'] = df[col].shift(1).rolling(window=max_lag).std()\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Create lagged features for controllable inputs\n",
    "df_lagged = create_lagged_features(df, controllable, max_lag=4)\n",
    "\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"After adding lags: {len(df_lagged.columns)}\")\n",
    "print(f\"\\nNew features per controllable input: 4 lags + 2 rolling = 6\")\n",
    "print(f\"Total new features: {len(controllable)} × 6 = {len(controllable) * 6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN (first 4 rows won't have lag data)\n",
    "rows_before = len(df_lagged)\n",
    "df_lagged = df_lagged.dropna()\n",
    "rows_after = len(df_lagged)\n",
    "\n",
    "print(f\"Dropped {rows_before - rows_after} rows (needed for lag calculation)\")\n",
    "print(f\"Remaining: {rows_after} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Features for Modeling\n",
    "\n",
    "Now we:\n",
    "1. Drop redundant columns\n",
    "2. Log-transform Starch Flow (and its lagged versions)\n",
    "3. Standardize all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop outputs/redundant\n",
    "df_model = df_lagged.drop(columns=drop_cols)\n",
    "\n",
    "# Log-transform Starch Flow columns (original + all lagged versions)\n",
    "starch_cols = [c for c in df_model.columns if 'Starch Flow' in c]\n",
    "for col in starch_cols:\n",
    "    df_model[col] = np.log1p(df_model[col])\n",
    "\n",
    "print(f\"Log-transformed {len(starch_cols)} Starch Flow columns\")\n",
    "\n",
    "# Define feature columns (everything except target)\n",
    "feature_cols = [c for c in df_model.columns if c != target]\n",
    "\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "df_model[feature_cols] = scaler.fit_transform(df_model[feature_cols])\n",
    "\n",
    "# Create X and y\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature stats (should be mean≈0, std≈1):\")\n",
    "print(X.describe().T[['mean', 'std']].head(5).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Time-Based Train/Test Split\n",
    "\n",
    "**Important:** For time series, we should NOT use random split.\n",
    "\n",
    "Why? If we randomly mix data, the model might see \"future\" data during training, which is cheating.\n",
    "\n",
    "Instead: Train on first 80% of time, test on last 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split (no shuffling!)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} rows ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Test set:     {len(X_test)} rows ({X_test.index.min()} to {X_test.index.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train with FLAML (Longer Budget)\n",
    "\n",
    "We give it 5 minutes this time — more features need more exploration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "automl.fit(\n",
    "    X_train, y_train,\n",
    "    task='regression',\n",
    "    metric='r2',\n",
    "    time_budget=300,  # 5 minutes\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest model: {automl.best_estimator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST SET PERFORMANCE (with time lags)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nR² Score:  {r2:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n",
    "print(f\"MAE:       {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Comparison with Notebook #3 ---\")\n",
    "print(f\"Without lags: R² = 0.359\")\n",
    "print(f\"With lags:    R² = {r2:.3f}\")\n",
    "print(f\"Improvement:  {(r2 - 0.359) / 0.359 * 100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax.set_xlabel('Actual % Silica')\n",
    "ax.set_ylabel('Predicted % Silica')\n",
    "ax.set_title(f'Actual vs Predicted (R² = {r2:.3f})')\n",
    "\n",
    "ax = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax.scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted % Silica')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/model_03_lagged_predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Which Lags Matter Most?\n",
    "\n",
    "Feature importance tells us which time lags the model found most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automl.model.estimator\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 20 Most Important Features:\")\n",
    "    print(importance.head(20).to_string(index=False))\n",
    "else:\n",
    "    importance = None\n",
    "    print(\"Feature importance not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which lag times are most important\n",
    "if importance is not None:\n",
    "    # Extract lag info from feature names\n",
    "    def get_lag_type(name):\n",
    "        if '_lag1' in name:\n",
    "            return 'lag1 (1h ago)'\n",
    "        elif '_lag2' in name:\n",
    "            return 'lag2 (2h ago)'\n",
    "        elif '_lag3' in name:\n",
    "            return 'lag3 (3h ago)'\n",
    "        elif '_lag4' in name:\n",
    "            return 'lag4 (4h ago)'\n",
    "        elif '_roll_mean' in name:\n",
    "            return 'rolling mean'\n",
    "        elif '_roll_std' in name:\n",
    "            return 'rolling std'\n",
    "        else:\n",
    "            return 'current (t=0)'\n",
    "    \n",
    "    importance['lag_type'] = importance['feature'].apply(get_lag_type)\n",
    "    \n",
    "    lag_importance = importance.groupby('lag_type')['importance'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nImportance by Lag Type:\")\n",
    "    print(\"=\"*40)\n",
    "    for lag, imp in lag_importance.items():\n",
    "        print(f\"  {lag}: {imp:.0f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    lag_importance.plot(kind='bar', ax=ax, color='steelblue')\n",
    "    ax.set_ylabel('Total Importance')\n",
    "    ax.set_title('Which Time Lags Matter Most?')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/processed/model_04_lag_importance.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Changed:\n",
    "1. Added lagged features (1-4 hours) for controllable inputs\n",
    "2. Added rolling mean and std (process stability)\n",
    "3. Used time-based split instead of random split\n",
    "4. Increased FLAML budget to 5 minutes\n",
    "\n",
    "### Key Insight:\n",
    "The lag analysis tells us the **process response time** — how long after a change do we see the effect in output quality.\n",
    "\n",
    "### For Operators:\n",
    "If lag2 or lag3 features are most important, it means changes take 2-3 hours to show up in lab results. This affects how they should:\n",
    "- Time their adjustments\n",
    "- Interpret feedback\n",
    "- Avoid over-correcting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
